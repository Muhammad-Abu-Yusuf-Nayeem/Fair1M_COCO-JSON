{"metadata":{"accelerator":"GPU","colab":{"provenance":[],"collapsed_sections":["TjhUaZQIEfhh","VOQ2WlVBHsOi","bZCDi5zi3Wtw","2ThzrJQL3boD","Bu6CxzKdlzOL"]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8442527,"sourceType":"datasetVersion","datasetId":4848388},{"sourceId":8590186,"sourceType":"datasetVersion","datasetId":4914442},{"sourceId":172155161,"sourceType":"kernelVersion"},{"sourceId":60118,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":48722,"modelId":46964}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#  Import Library","metadata":{"_uuid":"d8a5db3b-5bd4-44bd-b2ca-8e07b6f6688f","_cell_guid":"8ee52a1f-e1f5-4ccd-aad8-06e3aa02e943","id":"TjhUaZQIEfhh","trusted":true}},{"cell_type":"code","source":"import json\nimport os\nimport numpy as np\nimport matplotlib.patches as patches\nimport matplotlib.pyplot as plt\nfrom bs4 import BeautifulSoup\nimport PIL\nfrom PIL import Image\nimport torchvision\nfrom torchvision import transforms, datasets, models\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\nimport time\nimport random\nimport shutil\nimport xml.etree.ElementTree as ET\nfrom tqdm import tqdm\nimport utils_objectdetection as utils\nfrom utils_objectdetection import bbox_iou\nimport torch\n!pip install pydrive2 python-telegram-bot\n!pip install pydrive2\nimport torch.optim\nimport pkg_resources\nfrom datetime import date\nfrom pydrive2.auth import GoogleAuth\nfrom pydrive2.drive import GoogleDrive\nfrom oauth2client.service_account import ServiceAccountCredentials\nfrom telegram import Bot","metadata":{"_uuid":"df9cdcf5-21e3-4ca4-9298-792c87c589b5","_cell_guid":"9fa755ce-7d9e-4735-a197-79be0eab165c","collapsed":false,"id":"DwpmvwQlx6mS","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-06-03T08:05:15.511578Z","iopub.execute_input":"2024-06-03T08:05:15.512390Z","iopub.status.idle":"2024-06-03T08:05:40.597778Z","shell.execute_reply.started":"2024-06-03T08:05:15.512351Z","shell.execute_reply":"2024-06-03T08:05:40.596459Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pydrive2 in /opt/conda/lib/python3.10/site-packages (1.19.0)\nRequirement already satisfied: python-telegram-bot in /opt/conda/lib/python3.10/site-packages (21.2)\nRequirement already satisfied: google-api-python-client>=1.12.5 in /opt/conda/lib/python3.10/site-packages (from pydrive2) (2.125.0)\nRequirement already satisfied: oauth2client>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from pydrive2) (4.1.3)\nRequirement already satisfied: PyYAML>=3.0 in /opt/conda/lib/python3.10/site-packages (from pydrive2) (6.0.1)\nRequirement already satisfied: pyOpenSSL>=19.1.0 in /opt/conda/lib/python3.10/site-packages (from pydrive2) (23.3.0)\nRequirement already satisfied: httpx~=0.27 in /opt/conda/lib/python3.10/site-packages (from python-telegram-bot) (0.27.0)\nRequirement already satisfied: httplib2<1.dev0,>=0.19.0 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client>=1.12.5->pydrive2) (0.21.0)\nRequirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client>=1.12.5->pydrive2) (2.26.1)\nRequirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client>=1.12.5->pydrive2) (0.2.0)\nRequirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client>=1.12.5->pydrive2) (2.11.1)\nRequirement already satisfied: uritemplate<5,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client>=1.12.5->pydrive2) (3.0.1)\nRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx~=0.27->python-telegram-bot) (4.2.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx~=0.27->python-telegram-bot) (2024.2.2)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx~=0.27->python-telegram-bot) (1.0.5)\nRequirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx~=0.27->python-telegram-bot) (3.6)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx~=0.27->python-telegram-bot) (1.3.0)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx~=0.27->python-telegram-bot) (0.14.0)\nRequirement already satisfied: pyasn1>=0.1.7 in /opt/conda/lib/python3.10/site-packages (from oauth2client>=4.0.0->pydrive2) (0.5.1)\nRequirement already satisfied: pyasn1-modules>=0.0.5 in /opt/conda/lib/python3.10/site-packages (from oauth2client>=4.0.0->pydrive2) (0.3.0)\nRequirement already satisfied: rsa>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from oauth2client>=4.0.0->pydrive2) (4.9)\nRequirement already satisfied: six>=1.6.1 in /opt/conda/lib/python3.10/site-packages (from oauth2client>=4.0.0->pydrive2) (1.16.0)\nRequirement already satisfied: cryptography<42,>=41.0.5 in /opt/conda/lib/python3.10/site-packages (from pyOpenSSL>=19.1.0->pydrive2) (41.0.7)\nRequirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography<42,>=41.0.5->pyOpenSSL>=19.1.0->pydrive2) (1.16.0)\nRequirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.12.5->pydrive2) (1.62.0)\nRequirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.12.5->pydrive2) (3.20.3)\nRequirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.12.5->pydrive2) (2.31.0)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=1.12.5->pydrive2) (4.2.4)\nRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/conda/lib/python3.10/site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client>=1.12.5->pydrive2) (3.1.1)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx~=0.27->python-telegram-bot) (1.2.0)\nRequirement already satisfied: typing-extensions>=4.1 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx~=0.27->python-telegram-bot) (4.9.0)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography<42,>=41.0.5->pyOpenSSL>=19.1.0->pydrive2) (2.21)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.12.5->pydrive2) (3.3.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.12.5->pydrive2) (1.26.18)\nRequirement already satisfied: pydrive2 in /opt/conda/lib/python3.10/site-packages (1.19.0)\nRequirement already satisfied: google-api-python-client>=1.12.5 in /opt/conda/lib/python3.10/site-packages (from pydrive2) (2.125.0)\nRequirement already satisfied: oauth2client>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from pydrive2) (4.1.3)\nRequirement already satisfied: PyYAML>=3.0 in /opt/conda/lib/python3.10/site-packages (from pydrive2) (6.0.1)\nRequirement already satisfied: pyOpenSSL>=19.1.0 in /opt/conda/lib/python3.10/site-packages (from pydrive2) (23.3.0)\nRequirement already satisfied: httplib2<1.dev0,>=0.19.0 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client>=1.12.5->pydrive2) (0.21.0)\nRequirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client>=1.12.5->pydrive2) (2.26.1)\nRequirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client>=1.12.5->pydrive2) (0.2.0)\nRequirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client>=1.12.5->pydrive2) (2.11.1)\nRequirement already satisfied: uritemplate<5,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client>=1.12.5->pydrive2) (3.0.1)\nRequirement already satisfied: pyasn1>=0.1.7 in /opt/conda/lib/python3.10/site-packages (from oauth2client>=4.0.0->pydrive2) (0.5.1)\nRequirement already satisfied: pyasn1-modules>=0.0.5 in /opt/conda/lib/python3.10/site-packages (from oauth2client>=4.0.0->pydrive2) (0.3.0)\nRequirement already satisfied: rsa>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from oauth2client>=4.0.0->pydrive2) (4.9)\nRequirement already satisfied: six>=1.6.1 in /opt/conda/lib/python3.10/site-packages (from oauth2client>=4.0.0->pydrive2) (1.16.0)\nRequirement already satisfied: cryptography<42,>=41.0.5 in /opt/conda/lib/python3.10/site-packages (from pyOpenSSL>=19.1.0->pydrive2) (41.0.7)\nRequirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography<42,>=41.0.5->pyOpenSSL>=19.1.0->pydrive2) (1.16.0)\nRequirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.12.5->pydrive2) (1.62.0)\nRequirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.12.5->pydrive2) (3.20.3)\nRequirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.12.5->pydrive2) (2.31.0)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=1.12.5->pydrive2) (4.2.4)\nRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/conda/lib/python3.10/site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client>=1.12.5->pydrive2) (3.1.1)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography<42,>=41.0.5->pyOpenSSL>=19.1.0->pydrive2) (2.21)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.12.5->pydrive2) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.12.5->pydrive2) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.12.5->pydrive2) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.12.5->pydrive2) (2024.2.2)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#  Check GPU Availability","metadata":{"_uuid":"3f52c96f-96bb-4b85-9b2a-f476383f872c","_cell_guid":"ff67d9a5-5637-48cf-816c-b966fccb7950","id":"VOQ2WlVBHsOi","trusted":true}},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n    print('We will use the GPU:', torch.cuda.get_device_name(0))\n\nelse:\n    print('No GPU available, using the CPU instead.')\n    device = torch.device(\"cpu\")","metadata":{"_uuid":"34cfbfac-e96e-440c-b512-b4c469b2e38f","_cell_guid":"f70337b7-9e08-40be-b49c-aa71f137dfbf","collapsed":false,"id":"WVdkYTL5wljD","outputId":"d249be58-8066-4d2b-f402-3d3c7fc51516","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-06-03T08:05:40.600149Z","iopub.execute_input":"2024-06-03T08:05:40.600526Z","iopub.status.idle":"2024-06-03T08:05:40.609982Z","shell.execute_reply.started":"2024-06-03T08:05:40.600495Z","shell.execute_reply":"2024-06-03T08:05:40.609073Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"There are 1 GPU(s) available.\nWe will use the GPU: Tesla P100-PCIE-16GB\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Load Dataset","metadata":{}},{"cell_type":"code","source":"source_path = '/kaggle/input/xml-and-coco-json-dataset'\n\ndestination_path = '/kaggle/working/xml-and-coco-json-dataset'\n\nshutil.copytree(source_path, destination_path)\n\nprint(\"Dataset Loaded Successfully\")","metadata":{"execution":{"iopub.status.busy":"2024-06-03T08:05:40.611179Z","iopub.execute_input":"2024-06-03T08:05:40.611437Z","iopub.status.idle":"2024-06-03T08:05:40.702409Z","shell.execute_reply.started":"2024-06-03T08:05:40.611415Z","shell.execute_reply":"2024-06-03T08:05:40.699418Z"},"trusted":true},"execution_count":20,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)","Cell \u001b[0;32mIn[20], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m source_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input/xml-and-coco-json-dataset\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m destination_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/working/xml-and-coco-json-dataset\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopytree\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdestination_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset Loaded Successfully\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/shutil.py:559\u001b[0m, in \u001b[0;36mcopytree\u001b[0;34m(src, dst, symlinks, ignore, copy_function, ignore_dangling_symlinks, dirs_exist_ok)\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m os\u001b[38;5;241m.\u001b[39mscandir(src) \u001b[38;5;28;01mas\u001b[39;00m itr:\n\u001b[1;32m    558\u001b[0m     entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(itr)\n\u001b[0;32m--> 559\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_copytree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mentries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mentries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msymlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msymlinks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mignore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mignore_dangling_symlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_dangling_symlinks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mdirs_exist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdirs_exist_ok\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/shutil.py:457\u001b[0m, in \u001b[0;36m_copytree\u001b[0;34m(entries, src, dst, symlinks, ignore, copy_function, ignore_dangling_symlinks, dirs_exist_ok)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    455\u001b[0m     ignored_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m--> 457\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdirs_exist_ok\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    458\u001b[0m errors \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    459\u001b[0m use_srcentry \u001b[38;5;241m=\u001b[39m copy_function \u001b[38;5;129;01mis\u001b[39;00m copy2 \u001b[38;5;129;01mor\u001b[39;00m copy_function \u001b[38;5;129;01mis\u001b[39;00m copy\n","File \u001b[0;32m/opt/conda/lib/python3.10/os.py:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 225\u001b[0m     \u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exist_ok \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39misdir(name):\n","\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/kaggle/working/xml-and-coco-json-dataset'"],"ename":"FileExistsError","evalue":"[Errno 17] File exists: '/kaggle/working/xml-and-coco-json-dataset'","output_type":"error"}]},{"cell_type":"markdown","source":"# Test-Train Separation","metadata":{"_uuid":"718a74fe-ebfb-46c5-802a-0b56b5590d00","_cell_guid":"a55e5efb-0dd1-4463-b179-814a0e64761a","id":"bZCDi5zi3Wtw","trusted":true}},{"cell_type":"code","source":"random.seed(384)\n\nFAIR1M2 = '/kaggle/working/xml-and-coco-json-dataset/'\n\ncoco_json_path = os.path.join(FAIR1M2, 'Refined COCO2.json')\n\nwith open(coco_json_path, 'r') as f:\n    data = json.load(f)\n\nprint(\"Total images:\", len(data['images']))\n\n# Calculate total objects\ntotal_objects = len(data['annotations'])\nprint(\"Total objects:\", total_objects)\n\ntest_dir = os.path.join(FAIR1M2, 'test_images')\ntrain_dir = os.path.join(FAIR1M2, 'train_images')\n\nos.makedirs(test_dir, exist_ok=True)\n\n# Splitting ratio\ntest_ratio = 0.2  \n\nnum_images = len(data['images'])\nnum_images_test = int(num_images * test_ratio)\n\ntest_indices = random.sample(range(num_images), num_images_test)\n\n# Initialize lists for train and test data\ntrain_images = []\ntest_images = []\ntrain_annotations = []\ntest_annotations = []\n\n# Iterate through images and annotations\nfor img in data['images']:\n    if img['id'] in test_indices:\n        test_images.append(img)\n    else:\n        train_images.append(img)\n\n# Filter annotations based on the selected images\nfor annotation in data['annotations']:\n    if annotation['image_id'] in test_indices:\n        test_annotations.append(annotation)\n    else:\n        train_annotations.append(annotation)\n\n# Save test images and annotations to a JSON file\ntest_data = {'images': test_images, 'annotations': test_annotations, 'categories': data['categories']}\ntest_json_path = os.path.join(FAIR1M2, 'test.json')\n\nwith open(test_json_path, 'w') as test_file:\n    json.dump(test_data, test_file, indent=4)\n\nfor img in test_images:\n    img_name = img['file_name']\n    shutil.move(os.path.join(FAIR1M2, 'images', img_name), os.path.join(test_dir, img_name))\n\ntrain_data = {'images': train_images, 'annotations': train_annotations, 'categories': data['categories']}\ntrain_json_path = os.path.join(FAIR1M2, 'train.json')\n\nwith open(train_json_path, 'w') as train_file:\n    json.dump(train_data, train_file, indent=4)\n\n# Calculate train and test objects\ntrain_objects = len(train_annotations)\ntest_objects = len(test_annotations)\n\nprint(\"Train images:\", len(train_images))\nprint(\"Train objects:\", train_objects)\nprint(\"Test images:\", len(test_images))\nprint(\"Test objects:\", test_objects)","metadata":{"_uuid":"bfde10f1-095f-41a4-8790-3e0dd3b1ce7f","_cell_guid":"db754750-db1c-49ca-b7aa-d9a804b0f8e9","collapsed":false,"id":"jG9gk630gYqI","outputId":"b81671b6-f1d6-47d1-eca8-2ff4d6e0b9e0","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-06-03T08:05:40.703343Z","iopub.status.idle":"2024-06-03T08:05:40.703810Z","shell.execute_reply.started":"2024-06-03T08:05:40.703555Z","shell.execute_reply":"2024-06-03T08:05:40.703574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Defining the Dataset Class","metadata":{"_uuid":"d740298c-db88-478a-8319-5fbec936a829","_cell_guid":"4dea5467-daa3-4445-8ead-1ac43dca9758","id":"2ThzrJQL3boD","trusted":true}},{"cell_type":"code","source":"label_colors = {\n1: '#FF0000', # red\n2: '#008000', # green\n3: '#0000FF', # blue\n4: '#00FFFF', # cyan\n5: '#FF00FF', # magenta\n6: '#FFFF00', # yellow\n7: '#000000', # black\n8: '#FFFFFF', # white\n9: '#FFC080', # red-orange\n10: '#008080', # teal\n11: '#000080', # navy blue\n12: '#FFA500', # orange\n13: '#800080', # purple\n14: '#008040', # dark green\n15: '#FF00BF', # pink\n16: '#808000', # brown\n17: '#0080FF', # sky blue\n18: '#FFC0CB', # peach\n19: '#8000FF', # violet\n20: '#00FFFF', # cyan\n21: '#FFD700', # gold\n22: '#008000', # green\n23: '#4B0082', # indigo\n24: '#FF69B4', # hot pink\n25: '#20B2AA', # light sea green\n26: '#FFA07A', # light orange\n27: '#008000', # green\n28: '#FF00FF', # magenta\n29: '#00FF00', # lime\n30: '#FFC080', # red-orange\n31: '#008080', # teal\n32: '#000080', # navy blue\n33: '#FFA500', # orange\n34: '#800080', # purple\n35: '#008040', # dark green\n36: '#FF00BF', # pink\n37: '#808000', # brown\n}\n# label_colors = {i: '#2fc557' for i in range(1, 38)}\n\n\ndef generate_box(obj):\n    return [\n        float(obj['bbox'][0]),\n        float(obj['bbox'][1]),\n        float(obj['bbox'][0] + obj['bbox'][2]),\n        float(obj['bbox'][1] + obj['bbox'][3])\n    ]\n\ndef generate_label(obj):\n    name = obj['category_id']\n    return list(label_colors.keys()).index(name) + 1\n\n\n\n\ndef generate_target(image_id, json_data):\n    target = {\n        'boxes': [],\n        'labels': []\n    }\n    for annotation in json_data['annotations']:\n        if annotation['image_id'] == image_id:\n            xmin, ymin, xmax, ymax = annotation['bbox']\n            target['boxes'].append([xmin, ymin, xmax, ymax])\n            target['labels'].append(generate_label(annotation))\n    target['boxes'] = torch.as_tensor(target['boxes'], dtype=torch.float32)\n    target['labels'] = torch.as_tensor(target['labels'], dtype=torch.int64)\n    return target\n\ndef plot_image_from_output(img, annotation):\n    img = img.cpu().permute(1, 2, 0)\n    fig, ax = plt.subplots(1)\n    ax.imshow(img)\n\n    for idx, label in enumerate(annotation[\"labels\"]):\n        xmin, ymin, xmax, ymax = annotation[\"boxes\"][idx]\n        rect = patches.Rectangle(\n            (xmin, ymin), (xmax - xmin), (ymax - ymin),\n            linewidth=1, edgecolor=label_colors[label], facecolor='none'\n        )\n        ax.add_patch(rect)\n\n    plt.show()","metadata":{"_uuid":"721ac3f4-056e-434b-8d6a-fd4a53240038","_cell_guid":"3fd7164b-d5cc-4443-8fa5-04d59edafd20","collapsed":false,"id":"l0s7ZjbAEfhl","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-06-03T08:05:40.705651Z","iopub.status.idle":"2024-06-03T08:05:40.706025Z","shell.execute_reply.started":"2024-06-03T08:05:40.705840Z","shell.execute_reply":"2024-06-03T08:05:40.705855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MaskDataset(object):\n    def __init__(self, transforms, path, json_path):\n        self.transforms = transforms\n        self.path = path\n        self.imgs = list(sorted(os.listdir(self.path)))\n        self.json_path = json_path\n        self.json_data = json.load(open(json_path, 'r'))\n\n    def __getitem__(self, idx):\n        file_image = self.imgs[idx]\n        img_path = os.path.join(self.path, file_image)\n        img = Image.open(img_path).convert(\"RGB\")\n\n        # Generate Label\n        file_label = file_image[:-3] + 'jpg'\n        image_id = [img['id'] for img in self.json_data['images'] if img['file_name'] == file_label][0]\n        target = generate_target(image_id, self.json_data)\n\n        if self.transforms is not None:\n            img = self.transforms(img)\n\n        return img, target\n\n    def __len__(self):\n        return len(self.imgs)\n\ndata_transform = transforms.Compose([\n        transforms.ToTensor()\n    ])\n\ntrain_dataset = MaskDataset(data_transform, '/kaggle/working/xml-and-coco-json-dataset/images', '/kaggle/working/xml-and-coco-json-dataset/train.json')\ntest_dataset = MaskDataset(data_transform, '/kaggle/working/xml-and-coco-json-dataset/test_images', '/kaggle/working/xml-and-coco-json-dataset/test.json')\n\ndef collate_fn(batch):\n    return tuple(zip(*batch))\n\ntrain_data_loader = torch.utils.data.DataLoader(train_dataset, batch_size=3, collate_fn=collate_fn)\ntest_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=2, collate_fn=collate_fn)","metadata":{"_uuid":"9c23b290-cfdb-4dac-87d0-1f4bbe23af87","_cell_guid":"fcb4066d-39ca-4ceb-9821-b60908faf25f","collapsed":false,"id":"EtZuyC59veOa","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-06-03T08:05:40.707504Z","iopub.status.idle":"2024-06-03T08:05:40.707844Z","shell.execute_reply.started":"2024-06-03T08:05:40.707679Z","shell.execute_reply":"2024-06-03T08:05:40.707693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import Model","metadata":{"_uuid":"93e4b33c-aa33-4d80-af15-03e389085b3f","_cell_guid":"06194208-5ed8-4f16-93b0-cea107d948c6","id":"Bu6CxzKdlzOL","trusted":true}},{"cell_type":"code","source":"from torchvision.models.detection import FasterRCNN\nfrom torchvision.models.detection.rpn import AnchorGenerator\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n!pip install efficientnet_pytorch\nfrom efficientnet_pytorch import EfficientNet\n\nclass EfficientNetBackbone(torch.nn.Module):\n    def __init__(self, efficientnet_model):\n        super(EfficientNetBackbone, self).__init__()\n        self.features = efficientnet_model\n        self.out_channels = efficientnet_model._conv_head.out_channels\n\n    def forward(self, x):\n        x = self.features.extract_features(x)\n        return x\n\ndef get_model_instance_segmentation(num_classes):\n    # Load pre-trained EfficientNet-B2 model\n    efficientnet_model = EfficientNet.from_name('efficientnet-b2', num_classes=38)\n\n    # Define the Faster R-CNN model with EfficientNet backbone\n    backbone = EfficientNetBackbone(efficientnet_model)\n    model = FasterRCNN(\n        backbone,\n        num_classes=num_classes,\n        rpn_anchor_generator=AnchorGenerator(\n            sizes=((32, 64, 128, 256, 512),),\n            aspect_ratios=((0.5, 1.0, 2.0),)\n        ),\n    )\n\n    # Replace the box predictor with FastRCNNPredictor\n    in_features = model.roi_heads.box_predictor.cls_score.in_features\n    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n\n    return model","metadata":{"_uuid":"4926cf88-93dc-4098-ac36-b069ee56a51d","_cell_guid":"5779111d-f0ab-4936-84c7-56f6c01b767e","collapsed":false,"id":"R6anTbFtQLCh","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-06-03T08:05:40.708991Z","iopub.status.idle":"2024-06-03T08:05:40.709332Z","shell.execute_reply.started":"2024-06-03T08:05:40.709171Z","shell.execute_reply":"2024-06-03T08:05:40.709184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = get_model_instance_segmentation(38)\n\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nmodel.to(device)","metadata":{"_uuid":"63c88ee7-e729-4511-aabd-764cde20ffb1","_cell_guid":"21be3a12-be59-4d52-afeb-c8be0ae292bc","collapsed":false,"id":"bUOpks69QLE_","outputId":"01670d46-1034-4d38-ab25-5976aab3b263","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-06-03T08:05:40.710956Z","iopub.status.idle":"2024-06-03T08:05:40.711303Z","shell.execute_reply.started":"2024-06-03T08:05:40.711140Z","shell.execute_reply":"2024-06-03T08:05:40.711153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.is_available()","metadata":{"_uuid":"a86e59ce-0bd5-4787-a4df-434fcddcef6f","_cell_guid":"6a0c1be9-515d-414a-9223-49ddf7947bae","collapsed":false,"id":"wRL8qmNBaRgu","outputId":"5758295e-7a81-485d-d362-7289e1be9c82","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-06-03T08:05:40.712494Z","iopub.status.idle":"2024-06-03T08:05:40.712795Z","shell.execute_reply.started":"2024-06-03T08:05:40.712644Z","shell.execute_reply":"2024-06-03T08:05:40.712656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# GDrive-Telegram API Configuration","metadata":{}},{"cell_type":"code","source":"telegram_token = \"6753078681:AAEf5Q6L9Dlbs32axb7vvZxqhK_niaKjdwE\"\nchannel_name = \"-1002087711269\"  \nbot = Bot(token=telegram_token)\n\nasync def send_telegram_message(message):\n    await bot.send_message(chat_id=channel_name, text=message)\n\ndef upload_file_to_gdrive(file_from, file_to, folder_name):\n    gauth = GoogleAuth()\n    gauth.credentials = ServiceAccountCredentials.from_json_keyfile_name(\n        \"/kaggle/input/drive-credential/credentials.json\", scopes=['https://www.googleapis.com/auth/drive'])\n\n    drive = GoogleDrive(gauth)\n    today = date.today().strftime(\"%m/%d/%y\")\n\n    parent_directory_id = '1HDTRIbB9yF918oBtN5zWmFQHgFOiU-II'\n\n    folder_meta = {\n        \"title\":  folder_name,\n        \"parents\": [{'id': parent_directory_id}],\n        'mimeType': 'application/vnd.google-apps.folder'\n    }\n\n    # check if folder already exists or not\n    folder_id = None\n    foldered_list = drive.ListFile(\n        {'q':  \"'\"+parent_directory_id+\"' in parents and trashed=false\"}).GetList()\n\n    for file in foldered_list:\n        if (file['title'] == folder_name):\n            folder_id = file['id']\n\n    if folder_id is None:\n        folder = drive.CreateFile(folder_meta)\n        folder.Upload()\n        folder_id = folder.get(\"id\")\n\n    file1 = drive.CreateFile(\n        {'parents': [{\"id\": folder_id}], 'title': file_to})\n    \n    file1.SetContentFile(file_from)\n    file1.Upload()\n    \n    # Get the file ID\n    file_id = file1['id']\n    \n    file_link = f\"https://drive.google.com/uc?export=download&id={file_id}\"\n    \n    return file_link","metadata":{"execution":{"iopub.status.busy":"2024-06-03T08:05:40.715100Z","iopub.status.idle":"2024-06-03T08:05:40.715931Z","shell.execute_reply.started":"2024-06-03T08:05:40.715567Z","shell.execute_reply":"2024-06-03T08:05:40.715587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"#Copy Saved Model\nsource_path = '/kaggle/input/fair1m-model-checkpoints/pytorch/efficientnet-b2/7'\n\ndestination_path = '/kaggle/working/checkpoint/'\nshutil.copytree(source_path, destination_path)\n\nprint(\"Checkpoint Copied Successfully\")","metadata":{"execution":{"iopub.status.busy":"2024-06-03T08:05:40.717256Z","iopub.status.idle":"2024-06-03T08:05:40.717708Z","shell.execute_reply.started":"2024-06-03T08:05:40.717475Z","shell.execute_reply":"2024-06-03T08:05:40.717494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"folder_name = \"EfficientNet-B2\" \nstart_epoch = 31\nnum_epochs = 100\nparams = [p for p in model.parameters() if p.requires_grad]\noptimizer = torch.optim.SGD(params, lr=0.005,\n                                momentum=0.9, weight_decay=0.0005)","metadata":{"_uuid":"168b0e19-6536-4392-9976-7241ab0a8048","_cell_guid":"0955ca1d-3d31-4b86-92b4-49d5801186f3","collapsed":false,"id":"Zws-xQdwQLMZ","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-06-03T08:05:40.718746Z","iopub.status.idle":"2024-06-03T08:05:40.719108Z","shell.execute_reply.started":"2024-06-03T08:05:40.718907Z","shell.execute_reply":"2024-06-03T08:05:40.718920Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint_dir = '/kaggle/working/checkpoint/'\nif not os.path.exists(checkpoint_dir):\n    os.makedirs(checkpoint_dir)\n\ncheckpoint_path = f'/kaggle/working/checkpoint/checkpoint{start_epoch}.pt'\n\nif os.path.exists(checkpoint_path):\n    model.load_state_dict(torch.load(checkpoint_path))\n    print(\"Checkpoint loaded successfully.\")","metadata":{"execution":{"iopub.status.busy":"2024-06-03T08:05:40.719900Z","iopub.status.idle":"2024-06-03T08:05:40.720241Z","shell.execute_reply.started":"2024-06-03T08:05:40.720074Z","shell.execute_reply":"2024-06-03T08:05:40.720088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PIL.Image.MAX_IMAGE_PIXELS = None","metadata":{"execution":{"iopub.status.busy":"2024-06-03T08:05:40.722199Z","iopub.status.idle":"2024-06-03T08:05:40.722517Z","shell.execute_reply.started":"2024-06-03T08:05:40.722358Z","shell.execute_reply":"2024-06-03T08:05:40.722372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('----------------------train start--------------------------')\n\ncls_losses = []\nbox_losses = []\ntotal_losses = []\n\nasync def main():\n    for epoch in range(start_epoch, num_epochs):\n        start = time.time()\n        model.train()\n        \n        total_cls_loss = 0.0\n        total_box_loss = 0.0\n        total_epoch_loss = 0.0\n\n        for imgs, annotations in train_data_loader:\n            imgs = [img.to(device) for img in imgs]\n            annotations = [{k: v.to(device) for k, v in t.items()} for t in annotations]\n            loss_dict = model(imgs, annotations)\n            losses_batch = sum(loss for loss in loss_dict.values())\n            cls_loss = loss_dict['loss_classifier']\n            box_loss = loss_dict['loss_box_reg']\n\n            optimizer.zero_grad()\n            losses_batch.backward()\n            optimizer.step()\n\n            total_cls_loss += cls_loss.item()\n            total_box_loss += box_loss.item()\n            total_epoch_loss += losses_batch.item()\n\n\n        epoch_file_name = f'{folder_name}_checkpoint_epoch{epoch+1}.pt'\n        checkpoint_path = os.path.join(checkpoint_dir, epoch_file_name)\n        torch.save(model.state_dict(), checkpoint_path)\n\n        # Upload the file\n        file_link = upload_file_to_gdrive(checkpoint_path, epoch_file_name, folder_name)\n\n        # Send message to Telegram\n        message = f\"{folder_name} | epoch : {epoch+1}, cls_loss : {total_cls_loss}, box_loss : {total_box_loss}, total_loss : {total_epoch_loss}\\n{file_link}\"\n        await send_telegram_message(message)\n\n        cls_losses.append(total_cls_loss)\n        box_losses.append(total_box_loss)\n        total_losses.append(total_epoch_loss)\n\n        print(f'epoch : {epoch+1}, cls_loss : {total_cls_loss}, box_loss : {total_box_loss}, total_loss : {total_epoch_loss}, time : {time.time() - start}')\n\nawait main()\n","metadata":{"_uuid":"f6576d27-f14b-414f-a7ac-9d45ce10228d","_cell_guid":"3e496769-4561-440f-ad00-b64207c64923","collapsed":false,"id":"nWFbYKAWtha2","outputId":"fbbfc21b-e636-4889-d88c-31499b2dfe60","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-06-03T08:05:40.723780Z","iopub.status.idle":"2024-06-03T08:05:40.724192Z","shell.execute_reply.started":"2024-06-03T08:05:40.723970Z","shell.execute_reply":"2024-06-03T08:05:40.723985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting the loss\nplt.figure(figsize=(10, 6)) \nplt.plot(range(start_epoch, epoch + 1), losses, label='Training Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title(f'Training Loss on {folder_name} ({start_epoch+1}-{num_epochs} Epoch)')\n# plt.legend()\nplt.show()\n\n\n\n# # Plotting Manual  loss\n# losses = [4219.66845703125,\n#           3294.255126953125,\n#           2996.263916015625,\n#           2855.10693359375,\n#           2750.4365234375,\n#           2686.026123046875,\n#           2617.944580078125,\n#           2569.9990234375,\n#           2538.9892578125,\n#           2485.15966796875,\n#           2440.21533203125, \n#           2415.9052734375, \n#           2396.2783203125, \n#           2362.054443359375, \n#           2346.248046875, \n#           2315.4921875, \n#           2288.581298828125, \n#           2289.169921875, \n#           2254.004150390625, \n#           2246.160888671875,\n#           2244.7666015625,\n#           2210.5478515625,\n#           2205.06689453125,\n#           2182.842529296875,\n#           2185.711181640625,\n#           2174.51708984375,\n#           2141.72119140625,\n#           2134.73974609375,\n#           2135.479736328125,\n#           2104.87109375,\n#           2103.5703125,\n#           2091.90087890625,\n#           2093.547119140625,\n#           2053.4951171875,\n#           2050.3564453125,\n#           2047.2796630859375,\n#           2064.235107421875,\n#           2016.824951171875,\n#           2016.7198486328125,\n#           2016.572021484375,\n#           2005.3057861328125,\n#           2007.4322509765625,\n#           1999.246826171875,\n#           1979.5877685546875,\n#           1989.076416015625,\n#           1983.7818603515625,\n#           1936.830078125,\n#           1960.492431640625,\n#           1949.1075439453125,\n#           1944.2293701171875,\n#           1950.8743896484375,\n#           1945.679931640625,\n#           1937.458740234375,\n#           1939.6971435546875,\n#           1915.462890625,\n#           1913.741455078125,\n#           1915.2259521484375,\n#           1922.7769775390625,\n#           1905.7222900390625,\n#           1886.150390625\n#          ]\n\n# num_epochs = len(losses)\n\n\n# import matplotlib.pyplot as plt\n\n# plt.figure(figsize=(10, 6))\n# plt.plot(range(1, len(losses) + 1), losses, label='Training Loss')\n# plt.xlabel('Epoch')\n# plt.ylabel('Loss')\n# plt.title(f'Training Loss on ResNet-50 (1-60 Epoch)')\n# # plt.legend()\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-03T08:05:40.725753Z","iopub.status.idle":"2024-06-03T08:05:40.726100Z","shell.execute_reply.started":"2024-06-03T08:05:40.725916Z","shell.execute_reply":"2024-06-03T08:05:40.725930Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Testing","metadata":{"_uuid":"c3c73765-500d-406a-b6c3-7ab184edd994","_cell_guid":"67d3b49d-b74a-415f-a599-ffad817840c4","id":"8KSv7R17o0wz","trusted":true}},{"cell_type":"code","source":"# def make_prediction(model, img, threshold):\n#     model.eval()\n#     preds = model(img)\n#     for id in range(len(preds)) :\n#         idx_list = []\n\n#         for idx, score in enumerate(preds[id]['scores']) :\n#             if score > threshold :\n#                 idx_list.append(idx)\n\n#         preds[id]['boxes'] = preds[id]['boxes'][idx_list]\n#         preds[id]['labels'] = preds[id]['labels'][idx_list]\n#         preds[id]['scores'] = preds[id]['scores'][idx_list]\n\n#     return preds","metadata":{"_uuid":"f3eb84ba-ec0a-4826-a976-f5ab1883eca0","_cell_guid":"be4de3a2-21d9-4f27-b6e8-571530c9fd38","collapsed":false,"id":"Ywqv5--JlFbd","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-06-03T08:05:40.727191Z","iopub.status.idle":"2024-06-03T08:05:40.727488Z","shell.execute_reply.started":"2024-06-03T08:05:40.727338Z","shell.execute_reply":"2024-06-03T08:05:40.727350Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def plot_image_from_output(img, annotation):\n#     img = img.cpu().numpy().transpose(1, 2, 0)\n#     fig, ax = plt.subplots(1, figsize=(14, 14))\n#     ax.imshow(img)\n\n#     for idx, label in enumerate(annotation[\"labels\"]):\n#         xmin, ymin, xmax, ymax = annotation[\"boxes\"][idx].cpu().numpy()\n#         rect = patches.Rectangle(\n#             (xmin, ymin), (xmax - xmin), (ymax - ymin),\n#             linewidth=1, edgecolor=label_colors[label.item()], facecolor='none'\n#         )\n#         ax.add_patch(rect)\n\n#     plt.show()\n\n\n# random.seed(384)  \n\n# with torch.no_grad():\n#     total_images = len(test_data_loader.dataset)\n    \n#     # Select 10 random indices\n#     random_indices = random.sample(range(total_images), 10)\n    \n#     for idx in random_indices:\n#         imgs, annotations = test_data_loader.dataset[idx]\n#         imgs = [imgs.to(device)]\n\n#         pred = make_prediction(model, imgs, 0.5)\n\n#         print(\"Target : \", annotations['labels'])\n#         plot_image_from_output(imgs[0], annotations)\n#         print(\"Prediction : \", pred[0]['labels'])\n#         plot_image_from_output(imgs[0], pred[0])","metadata":{"execution":{"iopub.status.busy":"2024-06-03T08:05:40.729391Z","iopub.status.idle":"2024-06-03T08:05:40.729692Z","shell.execute_reply.started":"2024-06-03T08:05:40.729542Z","shell.execute_reply":"2024-06-03T08:05:40.729554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plot","metadata":{}},{"cell_type":"code","source":"# labels = []\n# preds_adj_all = []\n# annot_all = []\n\n# for im, annot in tqdm(test_data_loader, position = 0, leave = True):\n#     im = list(img.to(device) for img in im)\n\n#     for t in annot:\n#         labels += t['labels']\n\n#     with torch.no_grad():\n#         preds_adj = make_prediction(model, im, 0.5)\n#         preds_adj = [{k: v.to(torch.device('cpu')) for k, v in t.items()} for t in preds_adj]\n#         preds_adj_all.append(preds_adj)\n#         annot_all.append(annot)","metadata":{"_uuid":"3f888cb5-a2aa-4908-85ae-855ccacc6db1","_cell_guid":"afbae632-38b9-4705-9f6c-3d337a84092f","collapsed":false,"id":"TxpFLyoPLEJw","outputId":"0ac91f63-2dae-4a79-ae1d-68832f9f4f5c","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-06-03T08:05:40.730768Z","iopub.status.idle":"2024-06-03T08:05:40.731117Z","shell.execute_reply.started":"2024-06-03T08:05:40.730928Z","shell.execute_reply":"2024-06-03T08:05:40.730942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sample_metrics = []\n# for batch_i in range(len(preds_adj_all)):\n#     sample_metrics += utils.get_batch_statistics(preds_adj_all[batch_i], annot_all[batch_i], iou_threshold=0.5) \n\n# true_positives, pred_scores, pred_labels = [torch.cat(x, 0) for x in list(zip(*sample_metrics))]  # all the batches get concatenated\n# precision, recall, AP, f1, ap_class = utils.ap_per_class(true_positives, pred_scores, pred_labels, torch.tensor(labels))\n# mAP = torch.mean(AP)\n# print(f'mAP : {mAP}')\n# print(f'AP : {AP}')","metadata":{"_uuid":"7117564c-4ebc-42fc-ad13-d1427fba1198","_cell_guid":"977093e6-ad5b-4366-bb51-84ad8f8604dd","collapsed":false,"id":"N_TysIKH6QnE","outputId":"e1c2d06b-0d18-406c-d402-f86aef29b024","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-06-03T08:05:40.732631Z","iopub.status.idle":"2024-06-03T08:05:40.732962Z","shell.execute_reply.started":"2024-06-03T08:05:40.732802Z","shell.execute_reply":"2024-06-03T08:05:40.732816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def plot_iou_curve(outputs, targets):\n#     iou_scores = []\n#     total_objects = 0\n#     for output, annotations in zip(outputs, targets):\n#         if output is None:\n#             continue\n\n#         for sample_i in range(len(output)):\n#             true_positives = torch.zeros(output[sample_i]['boxes'].shape[0])\n\n#             target_labels = annotations[sample_i]['labels'] if len(annotations[sample_i]) else []\n#             total_objects += len(target_labels)\n#             if len(annotations[sample_i]):\n#                 detected_boxes = []\n#                 target_boxes = annotations[sample_i]['boxes']\n\n#                 for pred_i, (pred_box, pred_label) in enumerate(zip(output[sample_i]['boxes'], output[sample_i]['labels'])):\n#                     if len(detected_boxes) == len(target_labels):\n#                         break\n\n#                     if pred_label not in target_labels:\n#                         continue\n\n#                     iou, _ = bbox_iou(pred_box.unsqueeze(0), target_boxes).max(0)\n#                     if iou >= 0:\n#                         true_positives[pred_i] = 1\n#                         detected_boxes.append(_)\n#                         iou_scores.append(iou.item()) \n\n#     plt.figure(figsize=(10, 6))\n#     plt.hist(iou_scores, bins=50, density=True, alpha=0.75, edgecolor='black')\n#     plt.xlabel('IOU Score')\n#     plt.ylabel('Frequency')\n#     plt.title('IOU Distribution')\n#     plt.grid(True)\n#     plt.show()\n    \n#     print(\"Total number of objects used:\", total_objects)\n\n# plot_iou_curve(preds_adj_all, annot_all)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T08:05:40.733952Z","iopub.status.idle":"2024-06-03T08:05:40.734304Z","shell.execute_reply.started":"2024-06-03T08:05:40.734145Z","shell.execute_reply":"2024-06-03T08:05:40.734158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def plot_curves(true_positives, pred_scores, pred_labels, target_labels):\n#     # Sorting by confidence\n#     sorted_indices = torch.argsort(-pred_scores)\n#     true_positives = true_positives[sorted_indices]\n#     pred_scores = pred_scores[sorted_indices]\n#     pred_labels = pred_labels[sorted_indices]\n\n#     # Compute cumulative true positives and false positives\n#     cum_tp = torch.cumsum(true_positives, dim=0)\n#     cum_fp = torch.cumsum(1 - true_positives, dim=0)\n\n#     precision = cum_tp / (cum_tp + cum_fp + 1e-16)\n#     recall = cum_tp / (len(target_labels) + 1e-16)\n#     f1 = 2 * precision * recall / (precision + recall + 1e-16)\n\n#     # Precision-Confidence Curve\n#     plt.figure(figsize=(10, 6))\n#     plt.plot(pred_scores.cpu().numpy(), precision.cpu().numpy(), label=\"Precision\")\n#     plt.xlabel('Confidence')\n#     plt.ylabel('Precision')\n#     plt.title('Precision-Confidence Curve')\n#     plt.legend()\n#     plt.grid(True)\n#     plt.show()\n\n#     # Recall-Confidence Curve\n#     plt.figure(figsize=(10, 6))\n#     plt.plot(pred_scores.cpu().numpy(), recall.cpu().numpy(), label=\"Recall\")\n#     plt.xlabel('Confidence')\n#     plt.ylabel('Recall')\n#     plt.title('Recall-Confidence Curve')\n#     plt.legend()\n#     plt.grid(True)\n#     plt.show()\n\n#     # F1-Confidence Curve\n#     plt.figure(figsize=(10, 6))\n#     plt.plot(pred_scores.cpu().numpy(), f1.cpu().numpy(), label=\"F1 Score\")\n#     plt.xlabel('Confidence')\n#     plt.ylabel('F1 Score')\n#     plt.title('F1-Confidence Curve')\n#     plt.legend()\n#     plt.grid(True)\n#     plt.show()\n\n#     # Precision-Recall Curve\n#     plt.figure(figsize=(10, 6))\n#     plt.plot(recall.cpu().numpy(), precision.cpu().numpy(), label=\"Precision-Recall\")\n#     plt.xlabel('Recall')\n#     plt.ylabel('Precision')\n#     plt.title('Precision-Recall Curve')\n#     plt.legend()\n#     plt.grid(True)\n#     plt.show()\n\n# plot_curves(true_positives, pred_scores, pred_labels, torch.tensor(labels))","metadata":{"execution":{"iopub.status.busy":"2024-06-03T08:05:40.735452Z","iopub.status.idle":"2024-06-03T08:05:40.735763Z","shell.execute_reply.started":"2024-06-03T08:05:40.735597Z","shell.execute_reply":"2024-06-03T08:05:40.735609Z"},"trusted":true},"execution_count":null,"outputs":[]}]}